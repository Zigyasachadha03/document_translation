{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "natqlMt0Tb1h"
      },
      "source": [
        "## SetUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cZr9ogtHTil_",
        "outputId": "79e8ac9b-bd53-49cb-8949-cbda309a033c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WD3yP8nsk7f",
        "outputId": "cd2747ac-ce3a-454d-87cc-0cd7707b2cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-7e0b796c-84c5-00e2-d7e5-3bba01e3d086)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUj1bPvCTzzn",
        "outputId": "3cbadb25-4c69-4620-f605-249e17538b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "469D9-SZS44V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko7u_VDJUtGX",
        "outputId": "b424f141-6fe0-4cbf-e8e4-69931e2d684a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDZCeaFAT0ef"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhAomQAZUPsv"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEX4DBX7UM7C"
      },
      "outputs": [],
      "source": [
        "text_file = pd.read_csv('/content/drive/MyDrive/Document Translation/data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IXwekBJYVWzm",
        "outputId": "d170884f-050e-44cb-f670-4d70d453884d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  English  \\\n",
              "0                                                     Hi.   \n",
              "1                                                     Hi.   \n",
              "2                                                    Run!   \n",
              "3                                                    Run!   \n",
              "4                                                    Run!   \n",
              "...                                                   ...   \n",
              "362856  I know that adding sentences only in your nati...   \n",
              "362857  I know that adding sentences only in your nati...   \n",
              "362858  I know that adding sentences only in your nati...   \n",
              "362859  Doubtless there exists in this world precisely...   \n",
              "362860  Doubtless there exists in this world precisely...   \n",
              "\n",
              "                                                  Spanish  \n",
              "0                                                   Ciao!  \n",
              "1                                                   Ciao.  \n",
              "2                                                  Corri!  \n",
              "3                                                  Corra!  \n",
              "4                                                Correte!  \n",
              "...                                                   ...  \n",
              "362856  So che aggiungere frasi soltanto nella sua lin...  \n",
              "362857  So che aggiungere frasi solamente nella sua li...  \n",
              "362858  So che aggiungere frasi solamente nella sua li...  \n",
              "362859  Senza dubbio esiste in questo mondo proprio la...  \n",
              "362860  Senza dubbio esiste in questo mondo proprio la...  \n",
              "\n",
              "[362861 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3fccceb-e46c-464a-bc14-89ef37a336ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362856</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi soltanto nella sua lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362857</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362858</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362859</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362860</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>362861 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3fccceb-e46c-464a-bc14-89ef37a336ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3fccceb-e46c-464a-bc14-89ef37a336ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3fccceb-e46c-464a-bc14-89ef37a336ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text_file = text_file.drop('Attribution', axis = 1)\n",
        "text_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7NAbBAqWT1D",
        "outputId": "74aa25cc-df6e-489e-a73a-3d1a9dc9e34d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Hi.',\n",
              "  'Hi.',\n",
              "  'Run!',\n",
              "  'Run!',\n",
              "  'Run!',\n",
              "  'Who?',\n",
              "  'Wow!',\n",
              "  'Duck!',\n",
              "  'Duck!',\n",
              "  'Duck!'],\n",
              " ['Ciao!',\n",
              "  'Ciao.',\n",
              "  'Corri!',\n",
              "  'Corra!',\n",
              "  'Correte!',\n",
              "  'Chi?',\n",
              "  'Wow!',\n",
              "  'Amore!',\n",
              "  'Tesoro!',\n",
              "  'Immergiti!'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "eng_text = []\n",
        "spa_text = []\n",
        "\n",
        "for sent in text_file['English']:\n",
        "  eng_text.append(sent)\n",
        "\n",
        "for sent in text_file['Spanish']:\n",
        "  spa_text.append(sent)\n",
        "\n",
        "eng_text[:10], spa_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cU5Rl9WXIq-",
        "outputId": "28277355-c6c8-44fe-8f9e-cf9ae2bdde0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ciao!', '[start]Hi.[end]'),\n",
              " ('Ciao.', '[start]Hi.[end]'),\n",
              " ('Corri!', '[start]Run![end]'),\n",
              " ('Corra!', '[start]Run![end]'),\n",
              " ('Correte!', '[start]Run![end]'),\n",
              " ('Chi?', '[start]Who?[end]'),\n",
              " ('Wow!', '[start]Wow![end]'),\n",
              " ('Amore!', '[start]Duck![end]'),\n",
              " ('Tesoro!', '[start]Duck![end]'),\n",
              " ('Immergiti!', '[start]Duck![end]')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "text_pairs = []\n",
        "\n",
        "for eng, spa in zip(eng_text, spa_text):\n",
        "  eng = '[start]' + eng + '[end]'\n",
        "  text_pairs.append((spa, eng))\n",
        "\n",
        "text_pairs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCGXQ3mchd6Y"
      },
      "source": [
        "## Split into Training, Valiation and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDlHVKQtYELU",
        "outputId": "0e88e4a2-06c5-4be9-e963-b081e88f71ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Tom ha trascorso gli ultimi anni della sua vita a Boston.',\n",
              "  '[start]Tom spent the last years of his life in Boston.[end]'),\n",
              " ('Aveva un bambino sano.', '[start]She had a healthy baby.[end]'),\n",
              " ('Tom parla con le sue piante?', '[start]Does Tom talk to his plants?[end]'),\n",
              " ('La scuola inizia alle nove.', '[start]School starts at nine.[end]'),\n",
              " ('Tom si stava preparando per il lavoro.',\n",
              "  '[start]Tom was getting ready for work.[end]'),\n",
              " ('Perché vorresti aiutarmi?', '[start]Why would you want to help me?[end]'),\n",
              " ('Devo parlarvi.', '[start]I must speak to you.[end]'),\n",
              " (\"Il re regnò sul suo popolo per quarant'anni.\",\n",
              "  '[start]The king reigned over his people for forty years.[end]'),\n",
              " ('È bello essere tornata', \"[start]It's nice to be back.[end]\"),\n",
              " ('Non sto più lavorando per lei.',\n",
              "  \"[start]I'm not working for you anymore.[end]\")]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "text_pairs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq9mpFwDhjTX",
        "outputId": "9564b671-e209-4c3f-bc2f-25b155646a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(254002, 54429)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "  num_train_samples = int(0.70* len(text_pairs))\n",
        "  num_val_samples = int(0.15* len(text_pairs))\n",
        "\n",
        "  num_train_samples, num_val_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKk1wvTkiF82"
      },
      "outputs": [],
      "source": [
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples: num_val_samples+num_train_samples]\n",
        "test_pairs = text_pairs[num_val_samples+num_train_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5AqeCukic_s",
        "outputId": "84e64a42-fc29-4e06-9e6d-bcaa8f64b674"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(254002, 54429, 54430)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_pairs), len(val_pairs), len(test_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WAsWMiZi-2H"
      },
      "source": [
        "## Vectorizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eUyIULBiqIr"
      },
      "outputs": [],
      "source": [
        "strip_char = string.punctuation + \"¿\"\n",
        "strip_char = strip_char.replace(\"[\", \"\")\n",
        "strip_char = strip_char.replace(\"]\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8SOG7_Ii1z0"
      },
      "outputs": [],
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kamh5XNplls6"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "  lowercase = tf.strings.lower(input_string)\n",
        "  return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_char),\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIUM54qtmjzO",
        "outputId": "9519f659-de2d-4c97-d723-acc87c47a6eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tom ha trascorso gli ultimi anni della sua vita a Boston.',\n",
              " '[start]Tom spent the last years of his life in Boston.[end]')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "text_pairs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zdyKQoymWVP",
        "outputId": "8df6278a-75a2-44a8-8b06-70272f8f8b6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
              "array([b'tom ha trascorso gli ultimi anni della sua vita a boston',\n",
              "       b'[start]tom spent the last years of his life in boston[end]'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "custom_standardization(text_pairs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFgNJyE2mclA"
      },
      "outputs": [],
      "source": [
        "# Vectorization\n",
        "\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens = vocab_size,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = sequence_length,\n",
        "    standardize = custom_standardization\n",
        ")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens = vocab_size,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = sequence_length + 1,\n",
        "    standardize = custom_standardization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d0qzWZMnl5B"
      },
      "outputs": [],
      "source": [
        "train_spa_text = [pair[0] for pair in train_pairs]\n",
        "train_eng_text = [pair[1] for pair in train_pairs]\n",
        "\n",
        "spa_vectorization.adapt(train_spa_text)\n",
        "eng_vectorization.adapt(train_eng_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kXR1ytioO85",
        "outputId": "8555a3d4-2a05-453e-cb8b-0549b096bcd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
              "array([ 167,   11,  600, 3151,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "spa_vectorization(train_spa_text[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04TcXEQNohaI",
        "outputId": "2ae43903-adca-426d-a1ba-945562ea4da9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(21,), dtype=int64, numpy=\n",
              "array([  54,   86,    7, 3150, 2423,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "eng_vectorization(train_eng_text[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qA5Y3IuozhF",
        "outputId": "58b1c696-f551-4dba-a868-f84f09f4f7da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'encoder_inputs': <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
              "  array([[   2,   12, 1042,   93, 3073,  186,   92,   63,  227,    5,   70,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0]])>,\n",
              "  'decoder_inputs': <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
              "  array([[  5, 467,   6, 129, 390,  12,  43, 683,  10, 112,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0]])>},\n",
              " <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
              " array([[467,   6, 129, 390,  12,  43, 683,  10, 112,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "def format_datasets(spa, eng):\n",
        "  spa = spa_vectorization.call(spa)\n",
        "  eng = eng_vectorization.call(eng)\n",
        "  return ({\"encoder_inputs\": spa, \"decoder_inputs\": eng[:, :-1]}, eng[:, 1:])\n",
        "\n",
        "format_datasets([train_spa_text[0]], [train_eng_text[0]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uSDocmnyuWi",
        "outputId": "198174d6-d895-466c-9b54-4564f918dbe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([254002, 20]), TensorShape([254002, 21]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "  s = spa_vectorization(train_spa_text)\n",
        "  e = eng_vectorization(train_eng_text)\n",
        "\n",
        "  s.shape, e.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM1QyRkTp-as"
      },
      "outputs": [],
      "source": [
        "def make_datasets(pairs):\n",
        "  spa_text, eng_text = zip(*pairs)\n",
        "  spa_texts = list(spa_text)\n",
        "  eng_texts = list(eng_text)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((spa_texts, eng_texts))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(format_datasets)\n",
        "  return dataset.shuffle(2048).prefetch(16).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k00BAGtdq-P3"
      },
      "outputs": [],
      "source": [
        "train_ds = make_datasets(train_pairs)\n",
        "val_ds = make_datasets(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvjkLVRkRWXV",
        "outputId": "5472d722-3dcf-48d9-d34f-ad7be6c11ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XkUDVNGSGnh"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5y9f59OSDlM"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GvdhO0OS8o2"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZfiU7zOS8mp"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SViu7CvTLUY"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIkMvjwwSsD0"
      },
      "outputs": [],
      "source": [
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Uy4eWTTc9o",
        "outputId": "425520bf-b3bf-4691-e65a-44fff2ddae1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, None, 15000) dtype=float32 (created by layer 'model_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "decoder_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwlhtayOTgoJ"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8f32a0jTsAS",
        "outputId": "d41757ff-a53a-4e51-dd39-cdb17ca8da21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "3969/3969 [==============================] - 296s 72ms/step - loss: 3.3212 - accuracy: 0.5002 - val_loss: 2.4051 - val_accuracy: 0.6227\n",
            "Epoch 2/30\n",
            "3969/3969 [==============================] - 268s 68ms/step - loss: 2.2224 - accuracy: 0.6600 - val_loss: 1.8898 - val_accuracy: 0.7145\n",
            "Epoch 3/30\n",
            "3969/3969 [==============================] - 265s 67ms/step - loss: 1.9119 - accuracy: 0.7124 - val_loss: 1.7620 - val_accuracy: 0.7396\n",
            "Epoch 4/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.7957 - accuracy: 0.7332 - val_loss: 1.7078 - val_accuracy: 0.7504\n",
            "Epoch 5/30\n",
            "3969/3969 [==============================] - 265s 67ms/step - loss: 1.7240 - accuracy: 0.7462 - val_loss: 1.6543 - val_accuracy: 0.7627\n",
            "Epoch 6/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.6714 - accuracy: 0.7562 - val_loss: 1.6463 - val_accuracy: 0.7666\n",
            "Epoch 7/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.6279 - accuracy: 0.7641 - val_loss: 1.6130 - val_accuracy: 0.7711\n",
            "Epoch 8/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.5901 - accuracy: 0.7708 - val_loss: 1.6013 - val_accuracy: 0.7758\n",
            "Epoch 9/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.5582 - accuracy: 0.7763 - val_loss: 1.5636 - val_accuracy: 0.7846\n",
            "Epoch 10/30\n",
            "3969/3969 [==============================] - 264s 66ms/step - loss: 1.5270 - accuracy: 0.7818 - val_loss: 1.5740 - val_accuracy: 0.7839\n",
            "Epoch 11/30\n",
            "3969/3969 [==============================] - 263s 66ms/step - loss: 1.4993 - accuracy: 0.7863 - val_loss: 1.5705 - val_accuracy: 0.7862\n",
            "Epoch 12/30\n",
            "3969/3969 [==============================] - 263s 66ms/step - loss: 1.4751 - accuracy: 0.7906 - val_loss: 1.5642 - val_accuracy: 0.7873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1cdc85ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "epochs =30   # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "transformer.save('/content/drive/MyDrive/Document Translation/saved_model')\n",
        "\n",
        "# or you can specify a different file format such as TensorFlow SavedModel\n",
        "# model.save('/content/drive/MyDrive/Document Translation/saved_model', save_format='tf')\n",
        "# Save the model in HDF5 format\n",
        "transformer.save('/content/drive/MyDrive/Document Translation/saved_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pkEVv4CpYzC",
        "outputId": "0ea0910b-51d2-4f0d-cb4c-cb30aa61cc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-tnpe5NZcXG"
      },
      "outputs": [],
      "source": [
        "eng_vocab = eng_vectorization.get_vocabulary()\n",
        "eng_index_lookup = dict(zip(range(len(eng_vocab)), eng_vocab))\n",
        "max_decoded_sentence_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5a4kfCLcYhb"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = spa_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = eng_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = eng_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAtlR0I_cc5f",
        "outputId": "5e167565-1115-45b2-b76d-4ad4bea0cbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spanish Sentence: Sembrava che Tom e Mary fossero esausti.\n",
            "English Original Sentence: [start]It seemed Tom and Mary were exhausted.[end]\n",
            "English Translated Sentence: [start] looked tom and mary was exhausted[end]              \n"
          ]
        }
      ],
      "source": [
        "test_spa_texts = [pair[0] for pair in test_pairs]\n",
        "test_eng_texts = [pair[1] for pair in test_pairs]\n",
        "\n",
        "# for i in range(5):\n",
        "#     input_sentence = test_spa_texts[i]\n",
        "#     print(f\"input sentence: {input_sentence}\")\n",
        "#     translated = decode_sequence(input_sentence)\n",
        "#     print(f\"Original Sentence: {test_eng_texts[i]} , translated sentence: {translated}\")\n",
        "\n",
        "print(\"Spanish Sentence: \" + test_spa_texts[1000])\n",
        "print(\"English Original Sentence: \" + test_eng_texts[1000])\n",
        "print(\"English Translated Sentence: \" + decode_sequence(test_spa_texts[1000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCsFo1t4cc2_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}